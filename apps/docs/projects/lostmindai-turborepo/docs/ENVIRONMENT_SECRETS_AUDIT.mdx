<Info>
This content was automatically extracted from LostMindAI-TurboRepo.
For the most up-to-date information, refer to the source project.
</Info>

# üîê Environment Secrets Audit - LostMind AI

## Executive Summary

This document provides a comprehensive audit of all environment secrets required for the LostMind AI platform based on the current tech stack and implementation roadmap. Each secret is categorized by priority, service, and deployment environment.

## üö® Critical Secrets (Required for MVP)

### Database Configuration
```bash
# PostgreSQL with Row Level Security (RLS)
DATABASE_URL="postgresql://[user]:[password]@[host]:[port]/[database]?schema=public"
DIRECT_URL="postgresql://[user]:[password]@[host]:[port]/[database]?schema=public"

# Options for providers (choose one):
# - Supabase: postgresql://postgres:[password]@db.[project].supabase.co:5432/postgres
# - Neon: postgresql://[user]:[password]@[project].neon.tech/[database]
# - Google Cloud SQL: postgresql://[user]:[password]@[ip-address]/[database]
```

**Notes**: 
- DIRECT_URL is for Prisma migrations (bypasses connection pooling)
- DATABASE_URL is for application connections (uses pooling)
- **Uncertainty**: Which provider will you use? Each has different connection strings

### Authentication (Auth.js v5)
```bash
# Core Auth.js Configuration
NEXTAUTH_URL="https://lostmindai.com"  # Production
NEXTAUTH_SECRET="[32-char-random-string]"  # Generate: openssl rand -base64 32

# Google OAuth (Required)
GOOGLE_CLIENT_ID="[your-client-id].apps.googleusercontent.com"
GOOGLE_CLIENT_SECRET="[your-client-secret]"

# Optional OAuth Providers (for future)
GITHUB_CLIENT_ID=""
GITHUB_CLIENT_SECRET=""
```

**Setup Required**:
1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Create OAuth 2.0 credentials
3. Add authorized redirect URIs:
   - `http://localhost:3000/api/auth/callback/google` (dev)
   - `https://lostmindai.com/api/auth/callback/google` (prod)
   - `https://ask.lostmindai.com/api/auth/callback/google` (prod)

### AI Services (Google Generative AI)
```bash
# Google Gemini API (Primary AI Provider)
GOOGLE_GENERATIVE_AI_API_KEY="[your-gemini-api-key]"
GEMINI_API_KEY="[same-key-as-above]"  # Duplicate for compatibility

# Google Cloud Platform
GCP_PROJECT_ID="coral-muse-469919-m0"  # Your specific project
PROJECT_ID="coral-muse-469919-m0"  # Duplicate for compatibility
GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account-key.json"  # Local only

# Alternative AI Providers (Optional - for provider abstraction)
OPENAI_API_KEY=""  # If implementing OpenAI fallback
ANTHROPIC_API_KEY=""  # If implementing Claude fallback
```

**Notes**:
- Must use coral-muse project API keys
- Service account JSON file needed for local development
- **Uncertainty**: Will you implement multi-provider support immediately?

### Payment Processing (Stripe)
```bash
# Stripe API Keys
STRIPE_SECRET_KEY="sk_test_[your-test-key]"  # Test mode
STRIPE_PUBLISHABLE_KEY="pk_test_[your-test-key]"  # Client-side
NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY="pk_test_[your-test-key]"  # Next.js public

# Stripe Webhooks
STRIPE_WEBHOOK_SECRET="whsec_[your-webhook-secret]"

# Stripe Product/Price IDs (after creating in Stripe Dashboard)
STRIPE_PRICE_ID_BASIC="price_[basic-plan-id]"
STRIPE_PRICE_ID_PRO="price_[pro-plan-id]"
STRIPE_PRICE_ID_ENTERPRISE="price_[enterprise-plan-id]"
```

**Setup Required**:
1. Create products in Stripe Dashboard
2. Set up webhook endpoint: `https://lostmindai.com/api/webhooks/stripe`
3. Configure webhook events (customer.subscription.*, payment_intent.*, etc.)

## üìä Infrastructure & Deployment

### Vercel Configuration
```bash
# Vercel (Automatically set by Vercel)
VERCEL_URL=""  # Set automatically
VERCEL_ENV=""  # "production", "preview", or "development"
VERCEL_GIT_COMMIT_SHA=""  # Set automatically

# Custom Domains
NEXT_PUBLIC_APP_URL="https://lostmindai.com"
NEXT_PUBLIC_ASK_URL="https://ask.lostmindai.com"
NEXT_PUBLIC_ADMIN_URL="https://admin.lostmindai.com"
```

### Google Cloud Services
```bash
# Cloud Run Service URLs (FastAPI)
DOCUMENT_SERVICE_URL="https://document-processor-[hash]-uc.a.run.app"
CRAWLER_SERVICE_URL="https://crawler-engine-[hash]-uc.a.run.app"
AI_COMPUTE_SERVICE_URL="https://ai-compute-[hash]-uc.a.run.app"

# Google Cloud Pub/Sub (for async processing)
PUBSUB_TOPIC_DOCUMENTS="projects/coral-muse-469919-m0/topics/document-processing"
PUBSUB_TOPIC_CRAWL="projects/coral-muse-469919-m0/topics/web-crawl"
PUBSUB_TOPIC_AI_JOBS="projects/coral-muse-469919-m0/topics/ai-jobs"

# Google Cloud Storage (for file uploads)
GCS_BUCKET_NAME="lostmind-uploads"
GCS_BUCKET_DOCUMENTS="lostmind-documents"
GCS_BUCKET_CRAWL_CACHE="lostmind-crawl-cache"
```

**Notes**:
- Cloud Run URLs are generated after deployment
- **Uncertainty**: Exact bucket names and Pub/Sub topics need to be created

## üîç Monitoring & Analytics

### Analytics & Monitoring
```bash
# PostHog (Product Analytics)
NEXT_PUBLIC_POSTHOG_KEY="phc_[your-project-key]"
NEXT_PUBLIC_POSTHOG_HOST="https://app.posthog.com"  # or self-hosted URL

# Sentry (Error Tracking) - Optional but recommended
NEXT_PUBLIC_SENTRY_DSN="https://[key]@[org].ingest.sentry.io/[project]"
SENTRY_AUTH_TOKEN="[your-auth-token]"
SENTRY_ORG="lostmind-ai"
SENTRY_PROJECT="lostmind-web"

# Logging (Optional)
LOGFLARE_API_KEY=""  # If using Logflare
AXIOM_TOKEN=""  # If using Axiom
DATADOG_API_KEY=""  # If using Datadog
```

**Notes**:
- PostHog is free for <1M events/month
- **Uncertainty**: Which error tracking/logging service will you use?

## üåê Multi-Tenancy & Feature Flags

### Multi-Tenancy Configuration
```bash
# Soft Launch / Beta Testing
ALLOWED_TESTERS="email1@example.com,email2@example.com"  # CSV of allowed emails
FEATURE_FLAG_NEW_UI="false"
FEATURE_FLAG_AI_CHAT="true"
MAINTENANCE_MODE="false"

# Organization/Tenant Settings
DEFAULT_TENANT_ID="default"
ENABLE_MULTI_TENANCY="true"
MAX_ORGS_PER_USER="5"
```

## üìß Communication Services

### Email Service (Choose One)
```bash
# Option 1: Resend (Recommended - modern, developer-friendly)
RESEND_API_KEY="re_[your-api-key]"
EMAIL_FROM="noreply@lostmindai.com"

# Option 2: SendGrid
SENDGRID_API_KEY="SG.[your-api-key]"
SENDGRID_FROM_EMAIL="noreply@lostmindai.com"

# Option 3: AWS SES
AWS_SES_REGION="us-east-1"
AWS_SES_ACCESS_KEY_ID=""
AWS_SES_SECRET_ACCESS_KEY=""

# Option 4: SMTP (Generic)
SMTP_HOST="smtp.gmail.com"
SMTP_PORT="587"
SMTP_USER=""
SMTP_PASSWORD=""
```

**Notes**:
- Need to verify domain for sending
- **Uncertainty**: Which email service will you use?

## üîÑ Background Jobs & Queues

### Job Queue Configuration
```bash
# Redis (if using BullMQ or similar)
REDIS_URL="redis://default:[password]@[host]:6379"
REDIS_HOST="localhost"
REDIS_PORT="6379"
REDIS_PASSWORD=""

# Or Upstash Redis (Serverless)
UPSTASH_REDIS_REST_URL=""
UPSTASH_REDIS_REST_TOKEN=""
```

**Notes**:
- Only needed if implementing job queues
- **Uncertainty**: Will you use Redis or rely on Pub/Sub only?

## üóÑÔ∏è Vector Database (for RAG)

### Vector Database Configuration
```bash
# Option 1: pgvector (with existing PostgreSQL)
# No additional config needed - uses DATABASE_URL

# Option 2: Pinecone (Dedicated vector DB)
PINECONE_API_KEY=""
PINECONE_ENVIRONMENT="us-east-1"
PINECONE_INDEX_NAME="lostmind-embeddings"

# Option 3: Weaviate
WEAVIATE_URL=""
WEAVIATE_API_KEY=""

# Option 4: Qdrant
QDRANT_URL=""
QDRANT_API_KEY=""
```

**Notes**:
- pgvector is easiest (uses existing DB)
- **Uncertainty**: Will you use pgvector or dedicated vector DB?

## üîí Security & Compliance

### Security Headers & CORS
```bash
# CORS Configuration
CORS_ALLOWED_ORIGINS="https://lostmindai.com,https://ask.lostmindai.com"

# Content Security Policy
CSP_REPORT_URI="https://[your-csp-reporter].com"

# Rate Limiting
RATE_LIMIT_WINDOW_MS="900000"  # 15 minutes
RATE_LIMIT_MAX_REQUESTS="100"
```

## üöÄ Deployment-Specific Variables

### Development Only
```bash
# Development flags
NODE_ENV="development"
NEXT_PUBLIC_ENV="development"
SKIP_ENV_VALIDATION="false"
DEBUG="*"  # or specific namespaces
```

### Staging/Preview
```bash
NODE_ENV="production"  # Always production for builds
NEXT_PUBLIC_ENV="staging"
ENABLE_PREVIEW_MODE="true"
```

### Production
```bash
NODE_ENV="production"
NEXT_PUBLIC_ENV="production"
ENABLE_PREVIEW_MODE="false"
```

## üìù Environment Files Structure

```
.env.example          # Template with all variables (committed to git)
.env.local           # Local development (never committed)
.env.production      # Production values (in Vercel/Cloud Run)
.env.test            # Test environment (for CI/CD)
```

## ‚úÖ Implementation Checklist

### Phase 1: MVP (Required Now)
- [ ] Database URL (PostgreSQL)
- [ ] NextAuth configuration
- [ ] Google OAuth credentials
- [ ] Gemini API key
- [ ] Basic Stripe keys
- [ ] Vercel deployment

### Phase 2: Enhanced Features (Week 2)
- [ ] Cloud Run service URLs
- [ ] Google Cloud Storage buckets
- [ ] Email service (Resend/SendGrid)
- [ ] PostHog analytics
- [ ] Pub/Sub topics

### Phase 3: Scale & Monitor (Week 3)
- [ ] Sentry error tracking
- [ ] Redis for queues
- [ ] Vector database
- [ ] Advanced Stripe webhooks
- [ ] Multi-tenancy flags

## ‚ö†Ô∏è Security Best Practices

1. **Never commit real secrets** - Only .env.example
2. **Use different keys per environment** - Dev/Staging/Prod
3. **Rotate keys regularly** - Especially after team changes
4. **Use secret managers** - Vercel env vars, GCP Secret Manager
5. **Audit access logs** - Check for unauthorized usage
6. **Implement key rotation** - Automate where possible

## ü§î Questions Needing Answers

1. **Database Provider**: Supabase, Neon, or Google Cloud SQL?
2. **Email Service**: Resend, SendGrid, or AWS SES?
3. **Vector Database**: pgvector or dedicated service?
4. **Error Tracking**: Sentry, LogRocket, or custom?
5. **Job Queue**: Redis, Upstash, or Pub/Sub only?
6. **CDN/Storage**: Google Cloud Storage or alternatives?
7. **Multi-provider AI**: Implement fallbacks immediately or later?

## üìö Resources for Setup

- [Google Cloud Console](https://console.cloud.google.com) - OAuth, API keys
- [Stripe Dashboard](https://dashboard.stripe.com) - Payment setup
- [Vercel Dashboard](https://vercel.com) - Environment variables
- [PostHog](https://posthog.com) - Analytics setup
- [Resend](https://resend.com) - Email service

## üîÑ Next Steps

1. **Create accounts** for all required services
2. **Generate API keys** and store securely
3. **Create .env.local** from this template
4. **Configure Vercel** environment variables
5. **Test each service** connection individually
6. **Document** any custom configurations

---

**Last Updated**: December 2024
**Status**: Ready for implementation
**Priority**: Focus on Phase 1 secrets first