---
title: "LostMindAI-TurboRepo"
description: "This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository."
category: "guide"
project: "LostMind AI - Project Documentation"
lastUpdated: "2025-09-21"
tags: "guide,ai-services"
---

# ğŸ§  LostMind AI RAG Embeddings System Integration Guide

> **[ğŸ“š Documentation Hub](../README.md)** | **[ğŸ  Main README](../../README.md)** | **[ğŸ”§ All Guides](../README.md#integration-guides)** | **[ğŸ¤– Ask App Guide](INTEGRATION_GUIDE_FOR_ASK_APP.md)**

**SOURCE PROJECT**: `/Users/sumitm1/Documents/New Ongoing Projects/Back End Architecture for Turborepo with RAG Embeddings`

**TARGET LOCATIONS**: 
- `packages/rag/` - RAG utilities and interfaces
- `services/ai-compute/` - Heavy compute operations

## ğŸ¯ Mission Overview

You are tasked with migrating the **RAG Embeddings Backend Architecture** into the TurboRepo monorepo structure as both a shared package and compute service. This will serve as the foundational AI intelligence layer powering document understanding, semantic search, and contextual AI responses across all applications.

## ğŸ† Integration Objectives

### Primary Goals
1. **Migrate** RAG architecture into `packages/rag/` as shared utilities
2. **Deploy** compute-intensive operations to `services/ai-compute/`
3. **Implement** pgvector-powered similarity search with PostgreSQL
4. **Integrate** with Google Generative AI for embeddings and RAG processing
5. **Provide** scalable RAG infrastructure for all TurboRepo applications

### Success Criteria
- âœ… RAG package provides reusable utilities across all apps
- âœ… AI compute service handles embedding generation at scale
- âœ… pgvector integration enables fast similarity search
- âœ… Supports multiple document types (PDF, text, images, web pages)
- âœ… Sub-second query response times for most operations
- âœ… Horizontally scalable for enterprise document volumes

## ğŸ—ï¸ Target Architecture Integration

### Dual Integration Strategy
```
packages/rag/                    # â† SHARED UTILITIES
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                # Main exports
â”‚   â”œâ”€â”€ embedding/
â”‚   â”‚   â”œâ”€â”€ embedder.ts         # Embedding interfaces
â”‚   â”‚   â”œâ”€â”€ chunking.ts         # Document chunking
â”‚   â”‚   â””â”€â”€ similarity.ts       # Similarity calculations
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ retriever.ts        # Document retrieval
â”‚   â”‚   â”œâ”€â”€ ranking.ts          # Result ranking
â”‚   â”‚   â””â”€â”€ filtering.ts        # Content filtering
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”œâ”€â”€ document.ts         # Document models
â”‚   â”‚   â”œâ”€â”€ embedding.ts        # Embedding models
â”‚   â”‚   â””â”€â”€ query.ts           # Query models
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ preprocessing.ts    # Text preprocessing
â”‚       â”œâ”€â”€ postprocessing.ts   # Result processing
â”‚       â””â”€â”€ validation.ts       # Input validation

services/ai-compute/            # â† COMPUTE SERVICE
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                # FastAPI application
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py   # Embedding endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ rag.py         # RAG endpoints
â”‚   â”‚   â”‚   â””â”€â”€ search.py      # Search endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ embedder.py        # Embedding engine
â”‚   â”‚   â”œâ”€â”€ vectordb.py        # Vector database
â”‚   â”‚   â”œâ”€â”€ retriever.py       # RAG retrieval
â”‚   â”‚   â””â”€â”€ generator.py       # Response generation
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ document.py        # Document models
â”‚   â”‚   â”œâ”€â”€ embedding.py       # Embedding models
â”‚   â”‚   â””â”€â”€ response.py        # Response models
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ embedding_service.py
â”‚       â”œâ”€â”€ retrieval_service.py
â”‚       â””â”€â”€ generation_service.py
```

### RAG Tech Stack
- **Vector Database**: PostgreSQL with pgvector extension
- **Embeddings**: Google Generative AI (text-embedding-004 model)
- **Document Processing**: LangChain, PyPDF2, python-docx
- **Chunking Strategy**: Semantic and recursive text splitting
- **Search**: Hybrid vector + keyword search with BM25
- **Generation**: Google Gemini for RAG response synthesis
- **Caching**: Redis for embedding and query result caching

## ğŸ”„ Step-by-Step Migration Process

### Phase 1: Architecture Analysis & Planning

1. **Create Integration Branch**
   ```bash
   cd /Users/sumitm1/Documents/New\ Ongoing\ Projects/Back\ End\ Architecture\ for\ Turborepo\ with\ RAG\ Embeddings
   git checkout -b integration/turbo-repo-rag-system
   ```

2. **Analyze Current RAG Implementation**
   - **Document Processing**: How documents are currently parsed and chunked
   - **Embedding Strategy**: Current embedding models and vector dimensions
   - **Storage System**: How embeddings and metadata are stored
   - **Retrieval Logic**: Search and ranking algorithms implemented
   - **Generation Pipeline**: How contextual responses are generated
   - **Performance Characteristics**: Current latency and throughput metrics

3. **Define Integration Requirements**
   ```python
   # Document current RAG capabilities
   from dataclasses import dataclass
   from typing import List, Dict, Any, Optional
   from enum import Enum

   class DocumentType(Enum):
       PDF = "pdf"
       TEXT = "text"
       HTML = "html"
       MARKDOWN = "markdown"
       IMAGE = "image"
       AUDIO = "audio"

   @dataclass
   class RAGCapabilities:
       supported_document_types: List[DocumentType]
       max

---
*This content was automatically extracted from LostMind AI - Project Documentation. For the most up-to-date information, refer to the source project.*
